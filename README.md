# ğŸš€ GTD Terrorism Attack Classification Pipeline

[![Python](https://img.shields.io/badge/Python-3.10+-blue)](https://www.python.org)
[![scikit-learn](https://img.shields.io/badge/scikit-learn-1.3-green)](https://scikit-learn.org)
[![Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/rmahmood2233/GTD-Terrorism-Attack-Classification/blob/main/notebooks/Part 2_ PROJECT PIPELINE.ipynb)

---

## Table of Contents
- [Summary](#summary)
- [Results](#results)
- [Quick Start](#quick-start)
- [Project Structure](#project-structure)
- [Dataset](#dataset)
- [Reproducibility & Environment](#reproducibility--environment)
- [Responsible Use & Ethics](#responsible-use--ethics)
- [Contributing](#contributing)
- [Acknowledgments & Citation](#acknowledgments--citation)

---

## Summary
- **Goal:** Build a robust, modular pipeline to preprocess GTD records and classify attack types under heavy missingness and class imbalance.
- **Key features:** modular preprocessing (imputation, encoding, balancing), clear notebooks for EDA and pipeline, and exportable artifacts (figures & report).

> Note: This is a research project. Results depend strongly on preprocessing choices and the (sampled) dataset used.

---

## Results âœ…
Representative test results (see `reports/` for detailed tables and plots):

| Model | Test Acc | Macro F1 |
|-------|----------:|---------:|
| Random Forest | 0.9997 | 0.9986 |
| Logistic Regression | 0.9999 | 0.9986 |
| Gradient Boosting | **1.0000** | **1.0000** |

Visuals:

- Feature importance: `reports/figures/feature_importance_gb.png`
- Metrics tables/plots: `reports/figures/metrics_table.png`

## Quick Start ğŸ”§
Clone, install dependencies, and open the notebooks:

```bash
git clone https://github.com/YOUR_USERNAME/GTD-Terrorism-Attack-Classification.git
cd GTD-Terrorism-Attack-Classification
python -m venv .venv  # or use conda
.venv\Scripts\activate
pip install --upgrade pip
pip install -r requirements.txt

# Open notebooks
jupyter notebook "notebooks/Part 1_ EDA_GTD.ipynb"
jupyter notebook "notebooks/Part 2_ PROJECT PIPELINE.ipynb"
```

To run the pipeline in Colab, click the Colab badge at the top of this README and open `Part 2_ PROJECT PIPELINE.ipynb`.

---

## Project Structure
```
GTD-Terrorism-Attack-Classification/
â”œâ”€ data/
â”‚  â””â”€ external/           # place dataset samples here
â”œâ”€ notebooks/
â”‚  â”œâ”€ Part 1_ EDA_GTD.ipynb
â”‚  â””â”€ Part 2_ PROJECT PIPELINE.ipynb
â”œâ”€ reports/
â”‚  â””â”€ figures/            # plots and tables generated by notebooks
â”œâ”€ requirements.txt
â””â”€ README.md
```

---

## Dataset
This project uses the Global Terrorism Database (GTD) â€” a sensitive dataset. Please follow the GTD terms of use and citation guidelines when downloading and using the data.

Recommended workflow:
- Download GTD or a sample from the official source (START / Kaggle mirror as available).
- Place the CSV (or sample) at `data/external/GTD_sample.csv` for quick testing.

---

## Reproducibility & Environment ğŸ§ª
- Python 3.10+
- Install packages from `requirements.txt`.
- Set a fixed random seed in notebooks (e.g., `np.random.seed(0)` / `random_state=42`) to reproduce experiments.
- Results (especially metrics on imbalanced data) are sensitive to sampling, preprocessing, and balancing steps.

---

## Responsible Use & Ethics âš–ï¸
This repository deals with data about real-world violent events. Use it responsibly:
- Do not use this data or models to plan, promote, or facilitate harmful activities.
- Respect privacy and legal restrictions associated with GTD and any other datasets used.
- Document limitations and potential biases in analyses and models.

---

## Contributing
Suggestions to improve the project:
- Move pipeline code from notebooks to `src/` for reusability (e.g., `src/pipeline.py`).
- Add unit tests for data transformations and model training.
- Add a CI workflow for tests and linting.

If you'd like to contribute, please open an issue or submit a pull request.

---

## Acknowledgments & Citation ğŸ“š
Course: DS-311 Data Mining, NUST-SEECS.
If you use this work in research, please cite the GTD and note preprocessing choices in your methodology.

---

**Next steps / TODO**
- Upload generated figures to `reports/figures/` and update image paths in notebooks/README.
- Move reusable code into `src/` and add tests.
- Add LICENSE and contribution guidelines.

---

If this README is helpful, please â­ the repository and open issues for improvements.

